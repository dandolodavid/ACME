{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "import copy \n",
    "import warnings\n",
    "import sys\n",
    "import pickle\n",
    "import pyreadr as py\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from scipy.io import loadmat\n",
    "import shap\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "sys.path.append('../../')\n",
    "from ACME.ACME import ACME\n",
    "from ACME.visual_utils import * \n",
    "sys.path.remove('../../')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AcME-AD to explain IF in TEP dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We subsample the original dataset to resort to a typical anomaly detection scenario where anomalies are rare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_normal_simulations = 70 \n",
    "n_faulty_simulations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "normal_data = pd.read_csv('ad_industrial_datasets/TEP_FaultFree_Training_subsample_70_3.csv')\n",
    "fault_data = pd.read_csv('ad_industrial_datasets/TEP_Faulty_Training_subsample_70_3_removedfirst20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 20 datasets, each one containing only 1 specific fault \n",
    "data = []\n",
    "contaminations = []\n",
    "for i in range(20): \n",
    "    fault_data_i = fault_data[fault_data['faultNumber'] == i+1].reset_index(drop=True)\n",
    "    data.append(pd.concat([normal_data, fault_data_i], axis=0).reset_index(drop=True))\n",
    "    contaminations.append(len(fault_data_i)/len(data[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[0].columns[3:-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain fault 12\n",
    "Performances are good on fault 12 and we have prior knowledge on the fact that xmeas 11 is 'root cause' of the fault. \n",
    "[Harinarayan, R. Rajesh Alias, and S. Mercy Shalinie. \"XFDDC: eXplainable Fault Detection Diagnosis and Correction framework for chemical process systems.\" Process Safety and Environmental Protection 165 (2022): 463-474.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_12 = data[11].copy()\n",
    "contamination = contaminations[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters tuning \n",
    "from sklearn.model_selection import ParameterGrid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_samples': [64, 128, 256]\n",
    "}\n",
    "best_avg_prec = 0\n",
    "best_config = None\n",
    "\n",
    "for config in ParameterGrid(param_grid):\n",
    "    iforest = IsolationForest(contamination=contamination, random_state=0, n_jobs=-1, **config).fit(data_12[features])\n",
    "    data_12['Prediction'] = iforest.predict(data_12[features])\n",
    "    data_12['Prediction'] = data_12['Prediction'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "    avg_prec = average_precision_score(data_12['Target'], data_12['Prediction'])\n",
    "    if avg_prec > best_avg_prec: \n",
    "        best_avg_prec = avg_prec\n",
    "        best_config = config\n",
    "\n",
    "print(\"Best config: \", best_config, \" | Best avg prec: \", best_avg_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define score function needed for AcME-AD\n",
    "def if_score_function(model, X): \n",
    "    return 0.5 * (- model.decision_function(X) + 1)\n",
    "\n",
    "# train isolation forest with the best config\n",
    "ad_model = IsolationForest(contamination=contamination, random_state=0, n_jobs=-1, **best_config).fit(data_12[features])\n",
    "data_12['Prediction'] = ad_model.predict(data_12[features])\n",
    "data_12['Prediction'] = data_12['Prediction'].apply(lambda x: 1 if x == -1 else 0)\n",
    "data_12['Score'] = if_score_function(ad_model, data_12[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelSHAP explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_explain = data_12[data_12['Prediction'] == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to re-run KernelSHAP\n",
    "# # sample the 10% of the dataset data_12 but making sure that the proportion between samples with 'Target' == 0 and samples with 'Target' == 1 is preserved\n",
    "# data_12_normal = data_12[data_12['Target'] == 0].sample(frac=0.1, random_state=0)\n",
    "# data_12_faulty = data_12[data_12['Target'] == 1].sample(frac=0.1, random_state=0)\n",
    "\n",
    "# shap_background = pd.concat([data_12_normal, data_12_faulty], axis=0).reset_index(drop=True)\n",
    "\n",
    "# def if_score_function_shap(X): \n",
    "#     return 0.5 * (-ad_model.decision_function(X) + 1) \n",
    "    \n",
    "# shap_explainer = shap.KernelExplainer(if_score_function_shap, shap_background[features].values)\n",
    "# shap_values = shap_explainer.shap_values(data_to_explain[features])\n",
    "# df_shap_abs = pd.DataFrame(np.abs(shap_values), columns = features)\n",
    "\n",
    "# shap_rankings = df_shap_abs.rank(axis=1, ascending=False, method=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data\n",
    "# shap_rankings.to_csv('results/TEP_IF_rankings_SHAPKERNEL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results we have obtained\n",
    "shap_rankings = pd.read_csv('results/TEP_IF_rankings_SHAPKERNEL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_rank_counting = shap_rankings.apply(lambda x: x.value_counts()).fillna(0).astype(int)\n",
    "shap_rank_counting = shap_rank_counting / shap_rank_counting.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overall feature importance \n",
    "\n",
    "visual_dict = {\n",
    "    'xmeas_4': {\"color\": \"limegreen\", \"pattern\": \"\"}, \n",
    "    'xmeas_7': {'color': 'lightskyblue', 'pattern': '.'},  \n",
    "    'xmeas_11':{\"color\": \"midnightblue\", \"pattern\": \"x\"},\n",
    "    'xmeas_13':{\"color\": \"crimson\", \"pattern\": \"/\"},\n",
    "    'xmeas_38':{\"color\":\"mediumpurple\" , \"pattern\": \"\\\\\"}, \n",
    "    'xmv_2': {\"color\": \"aquamarine\", \"pattern\": \"+\"}, \n",
    "    'xmeas_20': {\"color\": \"rosyBrown\", \"pattern\": \"+\"}, \n",
    "    'xmv_9': {'color': 'orange', 'pattern' :'.'}\n",
    "}\n",
    "\n",
    "stacked_barplot_fig = feature_importance_distribution_barplot(shap_rank_counting, n_positions=5, threshold=0.05, color_pattern_dict = visual_dict)\n",
    "stacked_barplot_fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
