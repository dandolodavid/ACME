{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "import copy \n",
    "import warnings\n",
    "import sys\n",
    "import pickle\n",
    "import pyreadr as py\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from scipy.io import loadmat\n",
    "import shap\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
    "\n",
    "sys.path.append('../../')\n",
    "from ACME.ACME import ACME\n",
    "from ACME.visual_utils import * \n",
    "sys.path.remove('../../')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AcME-AD to explain IF in TEP dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We subsample the original dataset to resort to a typical anomaly detection scenario where anomalies are rare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_normal_simulations = 70 \n",
    "n_faulty_simulations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "normal_data = pd.read_csv('ad_industrial_datasets/TEP_FaultFree_Training_subsample_70_3.csv')\n",
    "fault_data = pd.read_csv('ad_industrial_datasets/TEP_Faulty_Training_subsample_70_3_removedfirst20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 20 datasets, each one containing only 1 specific fault \n",
    "faulty_data, data = [], []\n",
    "for i in range(20): \n",
    "    faulty_data.append(fault_data[fault_data['faultNumber'] == i+1].reset_index(drop=True))\n",
    "    data.append(pd.concat([normal_data, faulty_data[i]]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[0].columns[3:-1] \n",
    "contamination = faulty_data[0].shape[0] / data[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain fault 12\n",
    "Performances are good on fault 12 and we have prior knowledge on the fact that xmeas 11 is 'root cause' of the fault. \n",
    "[Harinarayan, R. Rajesh Alias, and S. Mercy Shalinie. \"XFDDC: eXplainable Fault Detection Diagnosis and Correction framework for chemical process systems.\" Process Safety and Environmental Protection 165 (2022): 463-474.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_12 = data[11].copy()\n",
    "best_config = {'max_samples': 256, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define score function needed for AcME-AD\n",
    "def if_score_function(model, X): \n",
    "    return 0.5 * (- model.decision_function(X) + 1)\n",
    "\n",
    "# train isolation forest with the best config\n",
    "ad_model = IsolationForest(contamination=contamination, random_state=0, n_jobs=-1, **best_config).fit(data_12[features])\n",
    "data_12['Prediction'] = ad_model.predict(data_12[features])\n",
    "data_12['Prediction'] = data_12['Prediction'].apply(lambda x: 1 if x == -1 else 0)\n",
    "data_12['Score'] = if_score_function(ad_model, data_12[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "n_normal_as_faulty = data_12[(data_12['Target'] == 0) & (data_12['Prediction'] == 1)].shape[0]\n",
    "n_faulty_as_faulty = data_12[(data_12['Target'] == 1) & (data_12['Prediction'] == 1)].shape[0]\n",
    "n_normal_as_normal = data_12[(data_12['Target'] == 0) & (data_12['Prediction'] == 0)].shape[0]\n",
    "n_faulty_as_normal = data_12[(data_12['Target'] == 1) & (data_12['Prediction'] == 0)].shape[0]\n",
    "\n",
    "print(\"Normal as faulty: \", n_normal_as_faulty, \" | Faulty as faulty: \", n_faulty_as_faulty, \" | Normal as normal: \", n_normal_as_normal, \" | Faulty as normal: \", n_faulty_as_normal)\n",
    "\n",
    "conf_matrix = np.array([[n_normal_as_normal, n_faulty_as_normal], [n_normal_as_faulty, n_faulty_as_faulty]])\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_explain = data_12[data_12['Prediction'] == 1].reset_index(drop=True).loc[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acme_time = time.time()\n",
    "acme = ACME(ad_model, 'Score', features, task='ad', score_function=if_score_function)\n",
    "acme = acme.explain(data_12, robust = True)\n",
    "local_exp = acme.explain_local(data_to_explain)\n",
    "local_exp.feature_importance(local=True, weights={'delta':0.3, 'change':0.3, 'distance':0.2, 'ratio':0.2})\n",
    "acme_time = time.time() - acme_time\n",
    "print(\"AcME-AD time: \", acme_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_backgrounds = []\n",
    "for i in [0.05, 0.1, 0.2, 0.5]: \n",
    "    data_12_normal = data_12[data_12['Target'] == 0].sample(frac=i, random_state=0)\n",
    "    data_12_faulty = data_12[data_12['Target'] == 1].sample(frac=i, random_state=0)\n",
    "\n",
    "    shap_backgrounds.append(pd.concat([data_12_normal, data_12_faulty], axis=0).reset_index(drop=True))\n",
    "\n",
    "def if_score_function_shap(X): \n",
    "    return 0.5 * (-ad_model.decision_function(X) + 1) \n",
    "\n",
    "shap_times = []\n",
    "for i in range(len(shap_backgrounds)): \n",
    "    shap_time = time.time()\n",
    "    shap_explainer = shap.KernelExplainer(if_score_function_shap, shap_backgrounds[i][features].values)\n",
    "    shap_values = shap_explainer.shap_values(data_to_explain[features])\n",
    "    shap_time = time.time() - shap_time\n",
    "    print(\"SHAP time: \", shap_time)\n",
    "    shap_times.append(shap_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
